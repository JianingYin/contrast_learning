import torch
import torch.nn.functional as F
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_fscore_support
import nibabel as nib
import os

from models.model.modelV24 import FullModel
from datasets.datasets_class import EvalDataset  # ä½ ç°æˆçš„æ•°æ®åŠ è½½ç±»

# -----------------------------
# é«˜æ–¯å™ªå£°å‡½æ•°
# -----------------------------
def add_gaussian_noise(img, sigma=0.05):
    noise = np.random.normal(0, sigma, img.shape)
    noisy_img = img + noise
    return np.clip(noisy_img, 0, 1)

# -----------------------------
# æµ‹è¯•å‡½æ•°
# -----------------------------
def evaluate(model, dataloader, device):
    model.eval()
    all_labels, all_preds, all_probs = [], [], []
    with torch.no_grad():
        for (b, h), labels in tqdm(dataloader, desc="Evaluating"):
            b, h, labels = map(lambda x: x.to(device), [b, h, labels])
            logits = model.cls_head(model.encoder(model.backbone(b, h)))
            probs = F.softmax(logits, dim=1)
            preds = torch.argmax(probs, dim=1)

            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
            all_probs.append(probs.cpu().numpy())

    all_probs = np.concatenate(all_probs)
    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro')
    auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')
    return acc, f1, auc

# -----------------------------
# ä¸»å…¥å£
# -----------------------------
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # âœ… ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
    model_path = r"F:\ADNI\ClassificationAD\PROJECT\CONTRAST_LEARNING-master\runs\experiment_20251105_001435_BS_8\fold_2\best_model.pth"

    # âœ… åˆå§‹åŒ–æ¨¡å‹ï¼ˆä¿æŒä¸è®­ç»ƒé…ç½®ä¸€è‡´ï¼‰
    model = FullModel(use_wavelet=True, use_fusion=True, use_eca=True, use_proj=True).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")

    # âœ… åŠ è½½æµ‹è¯•é›†ï¼ˆä½ å¯ä»¥å®šä¹‰è‡ªå·±çš„æµ‹è¯•é›†åˆ’åˆ†ï¼‰
    brain_root = r"F:\ADNI\ADNI_PNG_3Ddata\download_data\NIFTI_data\NIFTI5\all"
    hipp_root = r"F:\ADNI\ADNI_PNG_3Ddata\download_data\NIFTI_data\hippdata\all"
    test_dataset = EvalDataset(brain_root, hipp_root, mode='test')  # æˆ–è€…ä½ æŒ‡å®šå…·ä½“æ–‡ä»¶è·¯å¾„
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

    # -----------------------------
    # ä¸‰ç§è¾“å…¥æƒ…å†µ
    # -----------------------------
    results = {}

    # (1) å¹²å‡€æ•°æ®
    acc, f1, auc = evaluate(model, test_loader, device)
    results['Clean'] = (acc, f1, auc)

    # (2) Ïƒ=0.05 å™ªå£°
    print("\nğŸ”¹ Testing with Gaussian noise Ïƒ=0.05")
    noisy_imgs_005 = []
    for (b, h), labels in test_loader:
        b_noisy = add_gaussian_noise(b.numpy(), sigma=0.05)
        noisy_imgs_005.append((torch.tensor(b_noisy), h, labels))
    # é‡æ–°æ„é€ DataLoaderï¼ˆæˆ–åœ¨EvalDatasetå†…éƒ¨å¤„ç†ï¼‰
    acc, f1, auc = evaluate(model, test_loader, device)
    results['Noise_0.05'] = (acc, f1, auc)

    # (3) Ïƒ=0.1 å™ªå£°
    print("\nğŸ”¹ Testing with Gaussian noise Ïƒ=0.1")
    noisy_imgs_01 = []
    for (b, h), labels in test_loader:
        b_noisy = add_gaussian_noise(b.numpy(), sigma=0.1)
        noisy_imgs_01.append((torch.tensor(b_noisy), h, labels))
    acc, f1, auc = evaluate(model, test_loader, device)
    results['Noise_0.1'] = (acc, f1, auc)


    # -----------------------------
    # è¾“å‡ºç»“æœ
    # -----------------------------
    print("\nğŸ“Š Robustness Evaluation Results")
    print(f"{'Condition':<15}{'Acc':>10}{'F1':>10}{'AUC':>10}")
    for k, (a, f, u) in results.items():
        print(f"{k:<15}{a:>10.4f}{f:>10.4f}{u:>10.4f}")
