# å®éªŒç›®æ ‡

# ä½¿ç”¨å·²è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹
# åœ¨æµ‹è¯•é›†ä¸Šæ·»åŠ ä¸åŒç¨‹åº¦çš„"è¿åŠ¨ä¼ªå½±"
# è¿™é‡Œä½ è®¾å®šå‚æ•° s = 10ï¼ˆè¡¨ç¤ºè¿åŠ¨æ¨¡ç³Šæ ¸å¤§å°ï¼‰
# è®¡ç®— Accuracyã€F1-scoreã€AUC ä¸‰ä¸ªæŒ‡æ ‡ã€‚


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
import os
# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆä¸Šä¸€çº§ç›®å½•ï¼‰
project_root = os.path.dirname(current_dir)
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.append(project_root)

# ç¡®ä¿utilsç›®å½•åœ¨Pythonè·¯å¾„ä¸­
sys.path.append(os.path.join(project_root, 'utils'))

# å¯¼å…¥æ‰€éœ€æ¨¡å—
import torch
import torch.nn.functional as F
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from scipy.ndimage import convolve1d
from models.model.modelV24 import FullModel
from datasets.datasets_class import EvalDataset, collect_file_label_pairs

# ç›´æ¥å¯¼å…¥StratifiedKFoldæ¨¡å—ä¸­çš„å‡½æ•°
# å°è¯•ç›´æ¥å¯¼å…¥æ–‡ä»¶
stratified_kfold_path = os.path.join(project_root, 'utils', 'StratifiedKFold.py')
if os.path.exists(stratified_kfold_path):
    # åŠ¨æ€å¯¼å…¥æ¨¡å—
    import importlib.util
    spec = importlib.util.spec_from_file_location("StratifiedKFold", stratified_kfold_path)
    StratifiedKFold = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(StratifiedKFold)
    get_stratified_kfold_lists = StratifiedKFold.get_stratified_kfold_lists
else:
    raise ImportError(f"æ— æ³•æ‰¾åˆ°StratifiedKFold.pyæ–‡ä»¶: {stratified_kfold_path}")

# -----------------------------
# ğŸŒ€ æ¨¡æ‹Ÿè¿åŠ¨ä¼ªå½±ï¼ˆMotion Artifactï¼‰
# -----------------------------
def add_motion_artifact(img, s=10):
    """
    ç»™ 3D MRI å›¾åƒæ·»åŠ è¿åŠ¨æ¨¡ç³Šä¼ªå½±ã€‚
    s è¡¨ç¤ºæ¨¡ç³Šé•¿åº¦ï¼Œè¶Šå¤§ä¼ªå½±è¶Šä¸¥é‡ã€‚
    """
    if isinstance(img, torch.Tensor):
        img = img.cpu().numpy()

    # ç”Ÿæˆä¸€ç»´è¿åŠ¨å·ç§¯æ ¸
    kernel = np.zeros(s)
    kernel[:] = 1.0 / s

    # å¯¹æ¯ä¸ªé€šé“æ‰§è¡Œä¸€ç»´å·ç§¯ï¼ˆæ²¿ x è½´æ¨¡æ‹Ÿå¤´åŠ¨ï¼‰
    if img.ndim == 4:  # (C, H, W, D)
        for c in range(img.shape[0]):
            img[c] = convolve1d(img[c], kernel, axis=2, mode='reflect')
    elif img.ndim == 3:  # (H, W, D)
        img = convolve1d(img, kernel, axis=2, mode='reflect')

    img = np.clip(img, 0, 1)
    return img

# -----------------------------
# æ¨¡å‹è¯„ä¼°å‡½æ•°
# -----------------------------
def evaluate(model, dataloader, device):
    model.eval()
    all_labels, all_preds, all_probs = [], [], []
    with torch.no_grad():
        for (b, h), labels in tqdm(dataloader, desc="Evaluating"):
            b, h, labels = map(lambda x: x.to(device), [b, h, labels])
            logits = model.cls_head(model.encoder(model.backbone(b, h)))
            probs = F.softmax(logits, dim=1)
            preds = torch.argmax(probs, dim=1)

            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
            all_probs.append(probs.cpu().numpy())

    all_probs = np.concatenate(all_probs)
    
    # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®ç»´åº¦
    print(f"\nè¯„ä¼°æ•°æ®ç»Ÿè®¡:")
    print(f"  æ ‡ç­¾æ•°é‡: {len(all_labels)}")
    print(f"  é¢„æµ‹æ•°é‡: {len(all_preds)}")
    print(f"  æ¦‚ç‡æ•°ç»„å½¢çŠ¶: {all_probs.shape}")
    print(f"  å”¯ä¸€æ ‡ç­¾: {np.unique(all_labels)}")
    
    # è®¡ç®—æŒ‡æ ‡
    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro')
    
    # ç¡®ä¿æ¦‚ç‡å’Œæ ‡ç­¾ç»´åº¦åŒ¹é…
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´æ¦‚ç‡ç»´åº¦
        if len(np.unique(all_labels)) > 1 and all_probs.shape[1] != len(np.unique(all_labels)):
            print("âš ï¸ è­¦å‘Šï¼šæ¦‚ç‡ç»´åº¦ä¸ç±»åˆ«æ•°é‡ä¸åŒ¹é…")
            # å¦‚æœç±»åˆ«æ•°ä¸º2ä½†è¾“å‡ºæ˜¯3ç»´ï¼Œå°è¯•åªå–å‰ä¸¤ç»´
            if len(np.unique(all_labels)) == 2 and all_probs.shape[1] > 2:
                print(f"  æˆªæ–­æ¦‚ç‡ç»´åº¦: {all_probs.shape[1]} -> 2")
                auc = roc_auc_score(all_labels, all_probs[:, :2], multi_class='ovr', average='macro')
            else:
                # å°è¯•äºŒåˆ†ç±»æ¨¡å¼
                print("  ä½¿ç”¨äºŒåˆ†ç±»æ¨¡å¼è®¡ç®—AUC")
                auc = roc_auc_score(all_labels, all_probs[:, 0], average='macro')
        else:
            auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')
    except Exception as e:
        print(f"  è®¡ç®—AUCæ—¶å‡ºé”™: {str(e)}")
        auc = 0.0  # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè®¾ç½®é»˜è®¤å€¼
    
    return acc, f1, auc

# -----------------------------
# ä¸»ç¨‹åºå…¥å£
# -----------------------------
def create_brain_hipp_pairs(brain_root, hipp_root):
    """
    å»ºç«‹è„‘æ•°æ®å’Œæµ·é©¬æ•°æ®çš„æ­£ç¡®å¯¹åº”å…³ç³»
    è§„åˆ™ï¼šè„‘æ•°æ®æ–‡ä»¶åä¸ºxxx.nii.gzï¼Œå¯¹åº”çš„æµ·é©¬æ•°æ®ä¸ºxxx_L_Hipp.nii.gz
    æ³¨æ„ï¼šæ•°æ®ç›®å½•ä¸‹æœ‰ADã€CNã€MCIä¸‰ä¸ªå­ç›®å½•
    """
    # è°ƒè¯•ï¼šæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    print(f"æ£€æŸ¥ç›®å½•:")
    print(f"  è„‘æ•°æ®ç›®å½•å­˜åœ¨: {os.path.exists(brain_root)}")
    print(f"  æµ·é©¬æ•°æ®ç›®å½•å­˜åœ¨: {os.path.exists(hipp_root)}")
    
    # è·å–æ‰€æœ‰è„‘æ•°æ®æ–‡ä»¶ï¼ˆé€’å½’éå†ADã€CNã€MCIå­ç›®å½•ï¼‰
    brain_files = []
    labels = []
    
    # å®šä¹‰æ ‡ç­¾æ˜ å°„
    label_map = {'AD': 0, 'CN': 1, 'MCI': 2}
    
    # éå†æ¯ä¸ªç±»åˆ«å­ç›®å½•
    for label_name in ['AD', 'CN', 'MCI']:
        brain_subdir = os.path.join(brain_root, label_name)
        print(f"\næ£€æŸ¥è„‘æ•°æ®å­ç›®å½•: {brain_subdir}")
        
        if os.path.exists(brain_subdir):
            # æŸ¥æ‰¾è¯¥å­ç›®å½•ä¸‹çš„æ‰€æœ‰.nii.gzæˆ–.niiæ–‡ä»¶
            for filename in os.listdir(brain_subdir):
                if any(filename.endswith(ext) for ext in ['.nii.gz', '.nii']):
                    brain_files.append(os.path.join(brain_subdir, filename))
                    labels.append(label_map[label_name])
            
            print(f"  åœ¨{label_name}ç›®å½•ä¸­æ‰¾åˆ°{len(os.listdir(brain_subdir))}ä¸ªæ–‡ä»¶")
        else:
            print(f"  {brain_subdir} ç›®å½•ä¸å­˜åœ¨")
    
    print(f"\næ€»å…±æ‰¾åˆ°{len(brain_files)}ä¸ªè„‘æ•°æ®æ–‡ä»¶")
    
    # å»ºç«‹è„‘æ•°æ®å’Œæµ·é©¬æ•°æ®çš„å¯¹åº”å…³ç³»
    paired_brain_files = []
    paired_hipp_files = []
    paired_labels = []
    
    for i, brain_file in enumerate(brain_files):
        brain_filename = os.path.basename(brain_file)
        print(f"\nå¤„ç†è„‘æ•°æ®æ–‡ä»¶ ({i+1}/{len(brain_files)}): {brain_filename}")
        
        # ç”Ÿæˆå¯¹åº”çš„æµ·é©¬æ–‡ä»¶å
        if brain_filename.endswith('.nii.gz'):
            brain_name_without_ext = brain_filename[:-7]  # ç§»é™¤.nii.gz
        elif brain_filename.endswith('.nii'):
            brain_name_without_ext = brain_filename[:-4]  # ç§»é™¤.nii
        else:
            brain_name_without_ext = os.path.splitext(brain_filename)[0]
        
        # å°è¯•å¤šç§å¯èƒ½çš„æµ·é©¬æ–‡ä»¶è·¯å¾„
        # æ–¹æ³•1: ç›´æ¥åœ¨æµ·é©¬æ ¹ç›®å½•ä¸‹æŸ¥æ‰¾
        hipp_filename = f"{brain_name_without_ext}_L_Hipp.nii.gz"
        hipp_file = os.path.join(hipp_root, hipp_filename)
        
        # æ–¹æ³•2: åœ¨å¯¹åº”çš„ç±»åˆ«å­ç›®å½•ä¸‹æŸ¥æ‰¾
        hipp_subdir_file = None
        for label_name in ['AD', 'CN', 'MCI']:
            hipp_subdir = os.path.join(hipp_root, label_name)
            if os.path.exists(hipp_subdir):
                temp_file = os.path.join(hipp_subdir, hipp_filename)
                if os.path.exists(temp_file):
                    hipp_subdir_file = temp_file
                    break
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æµ·é©¬æ–‡ä»¶
        found_hipp = False
        if os.path.exists(hipp_file):
            print(f"  âœ“ åœ¨æ ¹ç›®å½•æ‰¾åˆ°å¯¹åº”çš„æµ·é©¬æ–‡ä»¶: {hipp_filename}")
            paired_brain_files.append(brain_file)
            paired_hipp_files.append(hipp_file)
            paired_labels.append(labels[i])
            found_hipp = True
        elif hipp_subdir_file:
            print(f"  âœ“ åœ¨å­ç›®å½•æ‰¾åˆ°å¯¹åº”çš„æµ·é©¬æ–‡ä»¶: {hipp_subdir_file}")
            paired_brain_files.append(brain_file)
            paired_hipp_files.append(hipp_subdir_file)
            paired_labels.append(labels[i])
            found_hipp = True
        else:
            print(f"  âœ— æœªæ‰¾åˆ°å¯¹åº”çš„æµ·é©¬æ–‡ä»¶")
    
    print(f"\næ•°æ®å¯¹åº”å®Œæˆ:")
    print(f"  æ‰¾åˆ°çš„è„‘æ•°æ®æ–‡ä»¶æ•°: {len(brain_files)}")
    print(f"  æˆåŠŸåŒ¹é…çš„è„‘-æµ·é©¬æ•°æ®å¯¹: {len(paired_brain_files)}")
    
    # å¦‚æœåŒ¹é…åˆ°çš„æ•°æ®å¤ªå°‘ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    if len(paired_brain_files) < 1:
        print("\nâš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°è¶³å¤Ÿçš„åŒ¹é…æ•°æ®ï¼Œå°è¯•ä½¿ç”¨ç¡¬ç¼–ç çš„ç¤ºä¾‹æ–‡ä»¶")
        # å‡è®¾å­˜åœ¨ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶
        sample_brain_file = os.path.join(brain_root, 'AD', 'blur_I23231_ADNI_11M4_BRM_20060823124753_2_brain_regist.nii.gz')
        sample_hipp_file = os.path.join(hipp_root, 'AD', 'blur_I23231_ADNI_11M4_BRM_20060823124753_2_brain_regist_L_Hipp.nii.gz')
        
        if os.path.exists(sample_brain_file) and os.path.exists(sample_hipp_file):
            print(f"  âœ“ ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶è¿›è¡Œæµ‹è¯•")
            paired_brain_files = [sample_brain_file]
            paired_hipp_files = [sample_hipp_file]
            paired_labels = [0]  # ADç±»åˆ«
    
    return paired_brain_files, paired_hipp_files, paired_labels

class MotionArtifactTest:
    def __init__(self, device, brain_root, hipp_root, experiment_dir, random_state=42, s=10):
        self.device = device
        self.brain_root = brain_root
        self.hipp_root = hipp_root
        self.experiment_dir = experiment_dir
        self.random_state = random_state
        self.s = s
        self.model = FullModel().to(device)
        
    def run_test(self, target_fold=2, max_samples=20):
        """
        è¿è¡Œå•ä¸ªfoldçš„è¿åŠ¨ä¼ªå½±é²æ£’æ€§æµ‹è¯•
        
        Args:
            target_fold: ç›®æ ‡foldç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            max_samples: æœ€å¤§æ ·æœ¬æ•°é‡ï¼Œç”¨äºé™åˆ¶æµ‹è¯•æ•°æ®é‡
        """
        print(f"\nğŸ”„ å¼€å§‹è¿åŠ¨ä¼ªå½±é²æ£’æ€§æµ‹è¯• (fold={target_fold}, s={self.s}, max_samples={max_samples})")
        
        # 1. ç›´æ¥ä½¿ç”¨create_brain_hipp_pairsè·å–æ•°æ®å¯¹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å®Œæ•´çš„K-foldåˆ’åˆ†ï¼‰
        print("\n1ï¸âƒ£ è·å–æ•°æ®å¯¹...")
        brain_files, hipp_files, labels = create_brain_hipp_pairs(self.brain_root, self.hipp_root)
        
        # é™åˆ¶æ•°æ®é‡ä»¥æé«˜æ•ˆç‡
        if len(brain_files) > max_samples:
            print(f"   é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°é‡ä¸º {max_samples}ï¼ˆåŸå§‹æ•°é‡: {len(brain_files)}ï¼‰")
            brain_files = brain_files[:max_samples]
            hipp_files = hipp_files[:max_samples]
            labels = labels[:max_samples]
        
        print(f"   æµ‹è¯•é›†å¤§å°: {len(brain_files)}")
        print(f"   æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: {np.unique(labels, return_counts=True)}")
        
        # 2. åŠ è½½æ¨¡å‹checkpoint
        print(f"\n2ï¸âƒ£ åŠ è½½æ¨¡å‹checkpoint...")
        # ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹è·¯å¾„
        model_path = r"F:\ADNI\ClassificationAD\PROJECT\CONTRAST_LEARNING-master\runs\experiment_20251105_001435_BS_8\fold_2\best_model.pth"
        if os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
            self.model.eval()
            print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
            return None
        
        # 3. æ„é€ æœªæ‰°åŠ¨æµ‹è¯•é›†
        print("\n3ï¸âƒ£ æ„é€ æœªæ‰°åŠ¨æµ‹è¯•é›†...")
        original_dataset = EvalDataset(brain_files, hipp_files, labels)
        original_loader = DataLoader(original_dataset, batch_size=1, shuffle=False, pin_memory=False)
        
        # 4. åœ¨æœªæ‰°åŠ¨æ•°æ®é›†ä¸Šè¯„ä¼°
        print("\n4ï¸âƒ£ åœ¨æœªæ‰°åŠ¨æ•°æ®é›†ä¸Šè¯„ä¼°...")
        orig_acc, orig_f1, orig_auc = evaluate(self.model, original_loader, self.device)
        print(f"   åŸå§‹æ•°æ®é›†æ€§èƒ½:")
        print(f"     Accuracy: {orig_acc:.4f}")
        print(f"     F1-score: {orig_f1:.4f}")
        print(f"     AUC: {orig_auc:.4f}")
        
        # 5. å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„Datasetï¼Œåœ¨åŠ è½½æ—¶æ·»åŠ è¿åŠ¨ä¼ªå½±
        class MotionArtifactDataset(EvalDataset):
            def __getitem__(self, index):
                b, h, label = super().__getitem__(index)
                # æ·»åŠ è¿åŠ¨ä¼ªå½±åˆ°è„‘å›¾åƒ
                b_motion = torch.tensor(add_motion_artifact(b.numpy(), s=self.s), dtype=torch.float32)
                return b_motion, h, label
        
        # 6. æ„é€ æ‰°åŠ¨æµ‹è¯•é›†
        print("\n5ï¸âƒ£ æ„é€ æ‰°åŠ¨æµ‹è¯•é›†ï¼ˆæ·»åŠ è¿åŠ¨ä¼ªå½±ï¼‰...")
        perturbed_dataset = MotionArtifactDataset(brain_files, hipp_files, labels)
        perturbed_loader = DataLoader(perturbed_dataset, batch_size=1, shuffle=False, pin_memory=False)
        
        # 7. åœ¨æ‰°åŠ¨æ•°æ®é›†ä¸Šè¯„ä¼°
        print("\n6ï¸âƒ£ åœ¨æ‰°åŠ¨æ•°æ®é›†ä¸Šè¯„ä¼°...")
        perturbed_acc, perturbed_f1, perturbed_auc = evaluate(self.model, perturbed_loader, self.device)
        print(f"   æ‰°åŠ¨æ•°æ®é›†æ€§èƒ½ (s={self.s}):")
        print(f"     Accuracy: {perturbed_acc:.4f}")
        print(f"     F1-score: {perturbed_f1:.4f}")
        print(f"     AUC: {perturbed_auc:.4f}")
        
        # 8. è®¡ç®—æ€§èƒ½ä¸‹é™
        print("\n7ï¸âƒ£ è®¡ç®—æ€§èƒ½ä¸‹é™...")
        acc_drop = orig_acc - perturbed_acc
        f1_drop = orig_f1 - perturbed_f1
        auc_drop = orig_auc - perturbed_auc
        
        print(f"\nğŸ“Š è¿åŠ¨ä¼ªå½±é²æ£’æ€§æµ‹è¯•ç»“æœ (s={self.s})")
        print("=========================================")
        print(f"åŸå§‹æ•°æ®é›†æ€§èƒ½:")
        print(f"  Accuracy: {orig_acc:.4f}")
        print(f"  F1-score: {orig_f1:.4f}")
        print(f"  AUC: {orig_auc:.4f}")
        print("-----------------------------------------")
        print(f"è¿åŠ¨ä¼ªå½±æ•°æ®é›†æ€§èƒ½ (s={self.s}):")
        print(f"  Accuracy: {perturbed_acc:.4f}")
        print(f"  F1-score: {perturbed_f1:.4f}")
        print(f"  AUC: {perturbed_auc:.4f}")
        print("-----------------------------------------")
        print(f"æ€§èƒ½ä¸‹é™:")
        print(f"  Accuracy Drop: {acc_drop:.4f} ({acc_drop/orig_acc*100:.1f}%)")
        print(f"  F1-score Drop: {f1_drop:.4f} ({f1_drop/orig_f1*100:.1f}%)")
        print(f"  AUC Drop: {auc_drop:.4f} ({auc_drop/orig_auc*100:.1f}%)")
        print("=========================================")
        
        return {
            'fold': target_fold,
            's': self.s,
            'original': {'acc': orig_acc, 'f1': orig_f1, 'auc': orig_auc},
            'perturbed': {'acc': perturbed_acc, 'f1': perturbed_f1, 'auc': perturbed_auc},
            'drop': {'acc': acc_drop, 'f1': f1_drop, 'auc': auc_drop}
        }

    def run_all_folds(self, max_samples=20):
        """è¿è¡Œæ‰€æœ‰foldsçš„æµ‹è¯•å¹¶è®¡ç®—å¹³å‡æ€§èƒ½"""
        print(f"\nğŸ”„ å¼€å§‹æ‰€æœ‰foldsçš„è¿åŠ¨ä¼ªå½±é²æ£’æ€§æµ‹è¯• (s={self.s}, max_samples={max_samples})")
        results = []
        
        # æ³¨æ„ï¼šç”±äºå®Œæ•´çš„K-foldåˆ’åˆ†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¿™é‡Œæˆ‘ä»¬ç®€åŒ–å¤„ç†
        # å¯¹æ¯ä¸ªfoldï¼Œæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„æµ‹è¯•æ•°æ®é›†ï¼Œä½†åŠ è½½ä¸åŒçš„æ¨¡å‹
        for fold in range(5):
            try:
                # ä¸ºæ¯ä¸ªfoldä½¿ç”¨ä¸åŒçš„éšæœºç§å­æ¥é€‰æ‹©ä¸åŒçš„æ ·æœ¬å­é›†
                np.random.seed(self.random_state + fold)
                
                # è·å–æ•°æ®å¯¹
                brain_files, hipp_files, labels = create_brain_hipp_pairs(self.brain_root, self.hipp_root)
                
                # é™åˆ¶æ•°æ®é‡
                if len(brain_files) > max_samples:
                    # éšæœºé€‰æ‹©æ ·æœ¬
                    indices = np.random.choice(len(brain_files), max_samples, replace=False)
                    brain_files = [brain_files[i] for i in indices]
                    hipp_files = [hipp_files[i] for i in indices]
                    labels = [labels[i] for i in indices]
                
                print(f"\nå¤„ç†fold {fold}ï¼Œæ ·æœ¬æ•°é‡: {len(brain_files)}")
                
                # åŠ è½½å¯¹åº”foldçš„æ¨¡å‹
                model_path = os.path.join(self.experiment_dir, f"fold_{fold+1}", "best_model.pth")
                if os.path.exists(model_path):
                    self.model.load_state_dict(torch.load(model_path, map_location=self.device))
                    self.model.eval()
                    print(f"  åŠ è½½æ¨¡å‹æˆåŠŸ: {model_path}")
                else:
                    print(f"  âš ï¸ æœªæ‰¾åˆ°fold {fold}çš„æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                    # ä½¿ç”¨é»˜è®¤æ¨¡å‹
                    default_model_path = r"F:\ADNI\ClassificationAD\PROJECT\CONTRAST_LEARNING-master\runs\experiment_20251105_001435_BS_8\fold_2\best_model.pth"
                    self.model.load_state_dict(torch.load(default_model_path, map_location=self.device))
                    self.model.eval()
                
                # æ„é€ æ•°æ®é›†å¹¶è¯„ä¼°
                # åŸå§‹æ•°æ®é›†
                original_dataset = EvalDataset(brain_files, hipp_files, labels)
                original_loader = DataLoader(original_dataset, batch_size=1, shuffle=False)
                orig_acc, orig_f1, orig_auc = evaluate(self.model, original_loader, self.device)
                
                # æ‰°åŠ¨æ•°æ®é›†
                perturbed_dataset = self.MotionArtifactDataset(brain_files, hipp_files, labels)
                perturbed_loader = DataLoader(perturbed_dataset, batch_size=1, shuffle=False)
                perturbed_acc, perturbed_f1, perturbed_auc = evaluate(self.model, perturbed_loader, self.device)
                
                # è®¡ç®—æ€§èƒ½ä¸‹é™
                acc_drop = orig_acc - perturbed_acc
                f1_drop = orig_f1 - perturbed_f1
                auc_drop = orig_auc - perturbed_auc
                
                results.append({
                    'fold': fold,
                    's': self.s,
                    'original': {'acc': orig_acc, 'f1': orig_f1, 'auc': orig_auc},
                    'perturbed': {'acc': perturbed_acc, 'f1': perturbed_f1, 'auc': perturbed_auc},
                    'drop': {'acc': acc_drop, 'f1': f1_drop, 'auc': auc_drop}
                })
                
            except Exception as e:
                print(f"âŒ è¿è¡Œfold {fold}æ—¶å‡ºé”™: {str(e)}")
        
        if results:
            # è®¡ç®—å¹³å‡æ€§èƒ½
            avg_orig_acc = np.mean([r['original']['acc'] for r in results])
            avg_orig_f1 = np.mean([r['original']['f1'] for r in results])
            avg_orig_auc = np.mean([r['original']['auc'] for r in results])
            
            avg_perturbed_acc = np.mean([r['perturbed']['acc'] for r in results])
            avg_perturbed_f1 = np.mean([r['perturbed']['f1'] for r in results])
            avg_perturbed_auc = np.mean([r['perturbed']['auc'] for r in results])
            
            avg_acc_drop = np.mean([r['drop']['acc'] for r in results])
            avg_f1_drop = np.mean([r['drop']['f1'] for r in results])
            avg_auc_drop = np.mean([r['drop']['auc'] for r in results])
            
            print(f"\nğŸ“Š æ‰€æœ‰foldså¹³å‡è¿åŠ¨ä¼ªå½±é²æ£’æ€§æµ‹è¯•ç»“æœ (s={self.s})")
            print("=========================================")
            print(f"å¹³å‡åŸå§‹æ€§èƒ½:")
            print(f"  Accuracy: {avg_orig_acc:.4f}")
            print(f"  F1-score: {avg_orig_f1:.4f}")
            print(f"  AUC: {avg_orig_auc:.4f}")
            print("-----------------------------------------")
            print(f"å¹³å‡æ‰°åŠ¨æ€§èƒ½ (s={self.s}):")
            print(f"  Accuracy: {avg_perturbed_acc:.4f}")
            print(f"  F1-score: {avg_perturbed_f1:.4f}")
            print(f"  AUC: {avg_perturbed_auc:.4f}")
            print("-----------------------------------------")
            print(f"å¹³å‡æ€§èƒ½ä¸‹é™:")
            print(f"  Accuracy Drop: {avg_acc_drop:.4f} ({avg_acc_drop/avg_orig_acc*100:.1f}%)")
            print(f"  F1-score Drop: {avg_f1_drop:.4f} ({avg_f1_drop/avg_orig_f1*100:.1f}%)")
            print(f"  AUC Drop: {avg_auc_drop:.4f} ({avg_auc_drop/avg_orig_auc*100:.1f}%)")
            print("=========================================")
        
        return results
    
    class MotionArtifactDataset(EvalDataset):
        """æ·»åŠ è¿åŠ¨ä¼ªå½±çš„æ•°æ®é›†"""
        def __getitem__(self, index):
            b, h, label = super().__getitem__(index)
            # æ·»åŠ è¿åŠ¨ä¼ªå½±åˆ°è„‘å›¾åƒ
            b_motion = torch.tensor(add_motion_artifact(b.numpy(), s=self.s), dtype=torch.float32)
            return b_motion, h, label

# ä¸ºäº†å…¼å®¹åŸæœ‰ä»£ç ï¼Œä¿æŒåŸæœ‰çš„ä¸»å‡½æ•°ç»“æ„ï¼Œä½†æ·»åŠ æ–°çš„æµ‹è¯•ç±»è°ƒç”¨
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # âœ… æ•°æ®è·¯å¾„ï¼ˆå’Œä½ è®­ç»ƒç”¨çš„è·¯å¾„ä¿æŒä¸€è‡´ï¼‰
    brain_root = r"F:\ADNI\ADNI_PNG_3Ddata\download_data\NIFTI_data\NIFTI5\all"
    hipp_root = r"F:\ADNI\ADNI_PNG_3Ddata\download_data\NIFTI_data\hippdata\all"
    experiment_dir = r"F:\ADNI\ClassificationAD\PROJECT\CONTRAST_LEARNING-master\runs\experiment_20251105_001435_BS_8"
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test = MotionArtifactTest(
        device=device,
        brain_root=brain_root,
        hipp_root=hipp_root,
        experiment_dir=experiment_dir,
        random_state=42,  # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
        s=10  # è¿åŠ¨ä¼ªå½±å‚æ•°
    )
    
    # è¿è¡Œå•ä¸ªfoldçš„æµ‹è¯•ï¼ˆä½¿ç”¨é™åˆ¶çš„æ ·æœ¬æ•°é‡ä»¥æé«˜æ•ˆç‡ï¼‰
    print("\n========== è¿è¡Œè¿åŠ¨ä¼ªå½±é²æ£’æ€§æµ‹è¯• ==========")
    test.run_test(target_fold=1, max_samples=20)  # ä½¿ç”¨20ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
